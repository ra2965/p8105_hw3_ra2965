---
title: "p8105_hw3_ra2965"
output: github_document
---
#Problem 1

```{r Problem1, message = FALSE}
#devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data(instacart)
```
Instacart is an online grocery service that allows people to shop online from local stores. This dataset describes the details of the online orders at Instacart. The dataset instacart contains `r nrow(instacart)` rows and `r ncol(instacart)` variables, where each row in the dataset is a product from an order. There is a single order per user in this dataset.

There are 15 variables in this dataset including the identifiers for the products, orders and customers, for example:

add_to_cart_order: order in which each product was added to cart

reordered: indicator of whether this prodcut has been ordered by this user in the past

eval_set: which evaluation set this order belongs in

order_number: the order sequence number for this user

order_dow: the day of the week on which the order was placed

order_hour_of_day: the hour of the day on which the order was placed

days_since_prior_order: days since the last order, capped at 30, 
product_name: name of the product

aisle: the name of the aisle

department: the name of the department

##giving illstrative examples of observations:
Take the first observation as an example: It records the product 49302, which is Bulgarian Yogurt, in the first order recorded of the user 112108. It belongs in the evaluation set of train. The order sequence number for this user is 4. The order was placed in the 10th hour in the day and it is the 4th day of the week. There were 9 days since the last order. The aisle ID is 120 and the name of the aisle is yogurt.The product is in the department of dairy eggs.

```{r aisles}
library(tidyverse)
instacart %>% 
  group_by(aisle) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n))
```

There are `r length(unique(pull(instacart, aisle_id)))` aisles, and the most items ordered from is "fresh vegetables".

```{r aisle plot, message = FALSE}
library(ggridges)

order_df = instacart %>% 
  group_by(aisle) %>% 
  summarize(n = n()) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = as.factor(aisle), 
         aisle = forcats::fct_reorder(aisle, n))
    
  ggplot(order_df,aes(x = aisle, y = n)) + 
    geom_point(alpha = 0.6) +
    labs(
    title = "The number of items ordered in each aisle",
    x = "aisle",
    y = "number of items") +
    scale_y_continuous(
    breaks  = c(20000, 40000,  60000,  80000,  100000, 120000, 140000, 160000), 
    limits = c(9000, 160000)
    ) + theme(axis.text.x = element_text(angle = 60, hjust = 1))

```



```{r aisle table, message = FALSE}

popular_product = instacart %>% 
  filter(aisle == "baking ingredients"|aisle == "dog food care"|aisle == "packaged vegetables fruits") %>% 
  group_by(aisle, product_name) %>%
  summarize(n_pop_pro = n()) %>%
  filter(min_rank(desc(n_pop_pro)) < 4) 
  knitr::kable(popular_product %>%
               arrange(desc(n_pop_pro)),
               col.names = c("Aisle", "Most Popular Items", "Number of Items"),
               format = "html",
               caption = "The 3 most popular items in each of the 3 aisles"
               )
 

```
```{r}
mean_hour = instacart %>% 
  filter(product_name == "Pink Lady Apples"|product_name == "Coffee Ice Cream") %>% 
  group_by(product_name, order_dow) %>%
  summarize(mean_hour_of_day = mean(order_hour_of_day)) %>%
  select(product_name, order_dow,mean_hour_of_day) %>%
  pivot_wider(
    names_from = "order_dow",
    values_from = "mean_hour_of_day"
  )
knitr::kable(mean_hour, 
             format = "html",
             caption = "The mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week",
             col.names = c("Product Name", "Sunday", "Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"),
             digits = 3)

```

#Problem 2
##Import dataset and tidy it:
```{r import data}
library(p8105.datasets)
data(brfss_smart2010) 

health = brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>%
  filter(response %in% c("Excellent","Very good", "Good", "Fair","Poor") ) %>%
  mutate(response = forcats::fct_relevel(response, c("Poor", "Fair", "Good","Very good","Excellent"))) 

```
##In 2002, which states were observed at 7 or more locations? 
```{r 2002 states:more than 7 locations}
num_loc_2002 = health %>% 
  filter(year == 2002) %>%
  group_by(locationabbr) %>% 
  summarise(obs_loc_num = n_distinct(locationdesc)) %>%
  filter(obs_loc_num >= 7)
knitr::kable(num_loc_2002,
             col.names = c("State Abbreviation", "Number of observed Locations"),
             format = "html",
             caption = "The states that were observed at 7 or more locations in 2002"
             )
```
In 2002,the abbreviation of states which were observed at 7 or more locations are shown in the table above.

##In 2010, which states were observed at 7 or more locations?
```{r 2010 states:more than 7 locations}
num_loc_2010 = health %>% filter(year == 2010) %>%
  group_by(locationabbr) %>% 
  summarise(obs_loc_num = n_distinct(locationdesc)) %>% 
  filter(obs_loc_num >= 7) 
knitr::kable(num_loc_2010,
             col.names = c("State Abbreviation", "Number of observed Locations"),
             format = "html",
             caption = "The states that were observed at 7 or more locations in 2010")
```
In 2010, the abbreviation of states which were observed at 7 or more locations are shown in the table above.

##Make a “spaghetti” plot of this average value over time within a state limiting to "Excellent"" responses:
```{r}
excellent_response = health %>% 
  filter(response == "Excellent") %>%
  group_by(locationabbr,year) %>%
  summarize(mean_data = mean(data_value,na.rm = TRUE)) 

excellent_response %>%
  ggplot(aes(x = year, y = mean_data, color = locationabbr)) + 
  geom_line() +
  labs(
    title = "Average data value over time within a state across years(%)",
    x = "Year",
    y = "Average data value (%)"
  ) 

```

##Make a two-panel plot 

The plot is showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State:
```{r ny boxplot, message=FALSE}

ny = health %>% 
  filter(locationabbr == "NY", year %in% c(2006,2010)) 
ggplot(ny, aes(x = response, y = data_value)) + 
  geom_boxplot() +
   facet_grid(~year) + 
  viridis::scale_fill_viridis(discrete = TRUE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(
    title = "Distribution of data_value for responses among locations in NY State",
    x = "Response",
    y = "Data Value (%)"
  ) 
  
```

#Problem 3
##Import and tidy the dataset:
```{r Problem3, message = FALSE}
accel_data = read_csv(file = "./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity", 
    names_prefix = "activity_",
    values_to = "counts"
              ) %>%
    mutate(
        activity = as.numeric(activity),
        day_indicator = case_when(
        day %in% c("Saturday","Sunday") ~ "weekend",
        day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday") ~ "weekday",
    TRUE ~ "" 
                                  ),
        day = forcats::fct_relevel(day, c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"))
    
          )

#and encode data with reasonable variable classes?

```
##Describe the resulting dataset:

This dataset contains five weeks of accelerometer data collected on a patient, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF). Since the activity counts are for each minute of a 24-hour day starting at midnight of 5 weeks, there are `r nrow(accel_data)` observations.

week: the week number

day_id: unique identifier for a specific day in the 5 weeks

day: indicates a specific day in a week

day_indicator: indicating a specific day is weekday or weekend

activity: the unique identfier for a activity test minute each time

count: the activity counts for each minute

##Create a table showing total activity for each day:
```{r create a table showing totals}
daytotal = accel_data %>%
  group_by(week, day) %>%
  summarise(day_tatal = sum(counts, na.rm = TRUE)) 


reader_friendly_table = daytotal %>% 
  pivot_wider(
  names_from = day,
  values_from = day_tatal
) 
  
knitr::kable(reader_friendly_table,
             format = "html",
             caption = "Total activity counts for each day",
             digits = 0)
```

There is no apparent trends in this table.

##Make a single-panel plot 
The plot shows the 24-hour activity time courses for each day and use color to indicate day of the week:
```{r}
accel_data %>% 
  ggplot(aes(x = activity, y = counts, color = day)) +
  geom_line() +
  scale_x_continuous(
    breaks = c(120, 240, 360,480,600,720,960,1200,1440)
  ) +
  labs(
    title = "The 24-hour activity time courses for each day",
    x = "Minutes",
    y = "Activity Counts"
  )
```

